{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partners Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the file\n",
    "df = pd.read_csv(r\"T:\\Dados\\Analytics\\0. Data Hub\\8. Banco de Dados\\Network Socios\\Receita Federal - Número de  Empresas por CNAE e UF - v2.csv\", sep=',', encoding='latin1', dtype=str)\n",
    "\n",
    "# Grouping the states (UFs) where each company has establishments\n",
    "ufs = df.groupby('cnpj_basico')['sigla_uf'].unique().reset_index()\n",
    "ufs['sigla_uf'] = ufs['sigla_uf'].apply(tuple)\n",
    "\n",
    "# Grouping the municipalities where each company has establishments\n",
    "df['nome_municÃ­pio'] = df['nome_municÃ­pio'].str.replace('\\\\r', '')\n",
    "municipalities = df.groupby('cnpj_basico')['nome_municÃ­pio'].unique().reset_index()\n",
    "municipalities['nome_municÃ­pio'] = municipalities['nome_municÃ­pio'].apply(tuple)\n",
    "\n",
    "# Grouping the primary fiscal CNAEs of each company's establishments\n",
    "primary_cnaes = df.groupby('cnpj_basico')['cnae_fiscal_primaria'].unique().reset_index()\n",
    "primary_cnaes['cnae_fiscal_primaria'] = primary_cnaes['cnae_fiscal_primaria'].apply(tuple)\n",
    "\n",
    "# Grouping the secondary fiscal CNAEs of each company's establishments\n",
    "def string_to_list(s):\n",
    "    if type(s) != str:\n",
    "        return []\n",
    "    return s.split(',')\n",
    "\n",
    "df['cnae_fiscal_secundaria'] = df['cnae_fiscal_secundaria'].apply(string_to_list)\n",
    "df['cnae_fiscal_secundaria'] = df['cnae_fiscal_secundaria'].apply(tuple)\n",
    "\n",
    "secondary_cnaes = df.groupby('cnpj_basico')['cnae_fiscal_secundaria'].unique().reset_index()\n",
    "secondary_cnaes['cnae_fiscal_secundaria'] = df['cnae_fiscal_secundaria'].apply(lambda x: tuple(set([val for val in x])))\n",
    "\n",
    "# Grouping the taxation forms of each company's establishments\n",
    "taxation_forms = df.groupby('cnpj_basico')['forma_tributacao'].unique().reset_index()\n",
    "taxation_forms['forma_tributacao'] = taxation_forms['forma_tributacao'].apply(tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df = df[['cnpj_basico', 'company_name', 'social_capital', 'partner_name', 'partner_cnpj_cpf']]\n",
    "\n",
    "df_ = pd.merge(df, ufs, on='cnpj_basico', how='left')\n",
    "df_ = pd.merge(df_, municipalities, on='cnpj_basico', how='left')\n",
    "df_ = pd.merge(df_, primary_cnaes, on='cnpj_basico', how='left')\n",
    "df_ = pd.merge(df_, secondary_cnaes, on='cnpj_basico', how='left')\n",
    "df_ = pd.merge(df_, taxation_forms, on='cnpj_basico', how='left')\n",
    "\n",
    "# Partner identifier\n",
    "df_['PARTNER_ID'] = df_['partner_name'] + df_['partner_cnpj_cpf']\n",
    "df_.drop(['partner_name', 'partner_cnpj_cpf'], axis=1, inplace=True)\n",
    "\n",
    "partners = df_.groupby('cnpj_basico')['PARTNER_ID'].unique().reset_index().rename(columns={'PARTNER_ID': 'PARTNERS'})\n",
    "partners['PARTNERS'] = partners['PARTNERS'].apply(tuple)\n",
    "\n",
    "df_ = pd.merge(df_, partners, how='left', on='cnpj_basico')\n",
    "\n",
    "# Removing duplicates\n",
    "df_ = df_.drop_duplicates()\n",
    "df_.rename(columns={'nome_municÃ­pio': 'municipalities'}, inplace=True)\n",
    "\n",
    "# Adding the number of companies each partner is involved with\n",
    "occurrences = df_['PARTNER_ID'].value_counts()\n",
    "df_['NUM_PARTNERSHIPS'] = df_['PARTNER_ID'].map(occurrences)\n",
    "\n",
    "# Removing partners that are associated with only one company\n",
    "df_ = df_[df_['NUM_PARTNERSHIPS'] > 1].reset_index().drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 1\n",
    "- Edges (common partners)\n",
    "- Vertices (companies)### Produto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vertices1(root, data, limit=None):\n",
    "\n",
    "    def extract_information(data, row, distance):\n",
    "        # Extract information from the row\n",
    "        current_cnpj = row['cnpj_basico']\n",
    "        company_name = row['razao_social_nome_emp']\n",
    "        partners_count = row['SOCIOS']\n",
    "        social_capital = row['capital_social']\n",
    "        states = row['sigla_uf']\n",
    "        municipalities = row['municipios']\n",
    "        primary_cnaes = row['cnae_fiscal_primaria']\n",
    "        secondary_cnaes = row['cnae_fiscal_secundaria']\n",
    "        partners = data.loc[data['cnpj_basico'] == current_cnpj, 'ID_SOCIO'].tolist()\n",
    "\n",
    "        return (current_cnpj, company_name, social_capital, states, municipalities, primary_cnaes, secondary_cnaes, distance, partners_count, partners)\n",
    "    \n",
    "    # Performs a breadth-first traversal starting from a cnpj_basico (the root of the graph)\n",
    "    visited = set()\n",
    "    queue = deque([(root, 0)])\n",
    "    vertices = []\n",
    "\n",
    "    while queue:\n",
    "        current_cnpj, distance = queue.popleft()\n",
    "\n",
    "        # Do not visit the same vertex twice\n",
    "        if current_cnpj in visited or (limit is not None and distance > limit):\n",
    "            continue\n",
    "\n",
    "        # Extract information of the current company\n",
    "        current_company = data[data['cnpj_basico'] == current_cnpj].iloc[0]\n",
    "        vertices.append(extract_information(data, current_company, distance))\n",
    "\n",
    "        visited.add(current_cnpj)\n",
    "\n",
    "        # Find all companies connected by partners\n",
    "        connected_companies = data[data['ID_SOCIO'].isin(vertices[-1][-1])]['cnpj_basico'].unique()\n",
    "\n",
    "        # Add the connected companies to the queue with the incremented distance\n",
    "        for company in connected_companies:\n",
    "            if company not in visited:\n",
    "                queue.append((company, distance + 1))\n",
    "\n",
    "    return pd.DataFrame(vertices, columns=['COMPANY', 'COMPANY_NAME', 'SOCIAL_CAPITAL', 'STATES', 'MUNICIPALITIES', 'PRIMARY_CNAEs', 'SECONDARY_CNAEs', 'LEVEL', 'TOTAL_PARTNERS', 'CONNECTED_PARTNERS']).sort_values('LEVEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edges(data):\n",
    "    edges = []\n",
    "    cnpjs = {row['cnpj_basico']: (row[-2], row[3], row[5], row[6]) for index, row in data.iterrows()}\n",
    "    \n",
    "    for _, group in data.groupby('ID_SOCIO'):\n",
    "        companies = group['cnpj_basico'].tolist()\n",
    "\n",
    "        if len(companies) > 1:\n",
    "            for name1, name2 in itertools.combinations(companies, 2):\n",
    "                common_partners = tuple(set(cnpjs[name1][0]).intersection(set(cnpjs[name2][0])))\n",
    "                num_common_partners = len(common_partners)\n",
    "                total_partners_union = len(set(cnpjs[name1][0]).union(set(cnpjs[name2][0])))\n",
    "                partners_percentage = num_common_partners / total_partners_union\n",
    "\n",
    "                uf_flag = 0 if len(set(cnpjs[name1][1]).intersection(set(cnpjs[name2][1]))) == 0 else 1\n",
    "\n",
    "                common_primary_cnaes = tuple(set(cnpjs[name1][2]).intersection(set(cnpjs[name2][2])))\n",
    "                num_primary_cnaes = len(common_primary_cnaes)\n",
    "                total_primary_cnaes = len(set(cnpjs[name1][2]).union(set(cnpjs[name2][2])))\n",
    "                primary_cnaes_percentage = num_primary_cnaes / total_primary_cnaes\n",
    "\n",
    "                common_secondary_cnaes = tuple(set(cnpjs[name1][3]).intersection(set(cnpjs[name2][3])))\n",
    "                num_secondary_cnaes = len(common_secondary_cnaes)\n",
    "                total_secondary_cnaes = len(set(cnpjs[name1][3]).union(set(cnpjs[name2][3])))\n",
    "                if total_secondary_cnaes != 0:\n",
    "                    secondary_cnaes_percentage = num_secondary_cnaes / total_secondary_cnaes\n",
    "                else:\n",
    "                    secondary_cnaes_percentage = None\n",
    "\n",
    "                edges.append((name1, name2, common_partners, num_common_partners, partners_percentage, uf_flag, common_primary_cnaes, primary_cnaes_percentage, common_secondary_cnaes, num_secondary_cnaes, secondary_cnaes_percentage))\n",
    "\n",
    "    return pd.DataFrame(edges, columns = ['COMPANY_1', 'COMPANY_2', 'COMMON_PARTNERS', 'NUM_COMMON_PARTNERS', 'PERCENTAGE_COMMON_PARTNERS', 'UF_FLAG', 'COMMON_PRIMARY_CNAES', 'PERCENTAGE_PRIMARY_CNAES',\n",
    "                                          'COMMON_SECONDARY_CNAES', 'NUM_COMMON_SECONDARY_CNAES', 'PERCENTAGE_SECONDARY_CNAES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_companies_connected_by_partners_V2(cnpj_b: str, data, distance_limit=None):\n",
    "    \n",
    "    # Vertices\n",
    "    df_vertices = generate_vertices1(cnpj_b, data, distance_limit)\n",
    "    df_vertices['PARENTS'] = \"\"\n",
    "\n",
    "    # Edges\n",
    "    df_edges = generate_edges(data[data['cnpj_basico'].isin(df_vertices['COMPANY'])])\n",
    "\n",
    "    # Adding reference to the parent node(s)\n",
    "    level_dict = df_vertices.set_index('COMPANY')['LEVEL'].to_dict()\n",
    "\n",
    "    for ind, edge in df_edges.iterrows():\n",
    "        if level_dict[edge['COMPANY_1']] - level_dict[edge['COMPANY_2']] == 1:\n",
    "            df_vertices.loc[df_vertices['COMPANY'] == edge['COMPANY_1'], 'PARENTS'] += (\",\" + edge['COMPANY_2'])\n",
    "        if level_dict[edge['COMPANY_2']] - level_dict[edge['COMPANY_1']] == 1:\n",
    "            df_vertices.loc[df_vertices['COMPANY'] == edge['COMPANY_2'], 'PARENTS'] += (\",\" + edge['COMPANY_1'])\n",
    "\n",
    "    return df_vertices, df_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices, edges = search_companies_connected_by_partners_V2('13930213', df_, 4)\n",
    "vertices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 2\n",
    "- Creation of the graph using networkx\n",
    "- Adjacency Matrix\n",
    "- Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(v, a):\n",
    "    \n",
    "    g = nx.Graph()\n",
    "\n",
    "    # Adding vertices to the graph\n",
    "    for ind, vertex in v.iterrows():\n",
    "        g.add_node(vertex[0], company_name=vertex[1], social_capital=vertex[2], states=vertex[3], municipalities=vertex[4],\n",
    "                   primary_cnaes=vertex[5], secondary_cnaes=vertex[6], level=vertex[7], total_partners=vertex[8], connected_partners=vertex[9])\n",
    "\n",
    "    # Adding edges to the graph\n",
    "    for ind, edge in a.iterrows():\n",
    "        g.add_edge(edge[0], edge[1], common_partners=edge[2], common_primary_cnaes=edge[6], common_secondary_cnaes=edge[8], num_common_partners=edge[3], partners_percentage=edge[4], \n",
    "                   uf_weight=edge[5], primary_cnaes_weight=edge[7], secondary_cnaes_weight=edge[9], secondary_cnaes_percentage=edge[10])\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generate_graph(vertices, edges)\n",
    "\n",
    "# Adjacency Matrix\n",
    "nx.to_pandas_adjacency(g, weight='secondary_cnaes_percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paths(g, source, target, cut_off=7, weight='num_common_partners'):\n",
    "\n",
    "    # Check if the source and target nodes are in the graph\n",
    "    if source not in g.nodes() or target not in g.nodes():\n",
    "        raise ValueError(\"The source and target nodes MUST be in the graph.\")\n",
    "\n",
    "    # Find all simple paths between the source and target\n",
    "    paths = list(nx.all_simple_paths(g, source=source, target=target, cutoff=cut_off))\n",
    "\n",
    "    # Return\n",
    "    res = []\n",
    "    for path in paths:\n",
    "        path_length = len(path) - 1  # The path length is the number of edges\n",
    "        company_names = [g.nodes[node]['company_name'] for node in path]\n",
    "        total_weight = sum(g[path[i]][path[i + 1]][weight] for i in range(path_length))\n",
    "        common_partners = list(g[path[i]][path[i + 1]]['common_partners'] for i in range(path_length))\n",
    "        \n",
    "        res.append((path, company_names, common_partners, path_length, total_weight))\n",
    "    \n",
    "    def sorting_key(tup):\n",
    "        return (tup[-2], -tup[-1])\n",
    "    \n",
    "    return sorted(res, key=sorting_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = find_paths(g, '13930213', '37228135')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top5(paths):\n",
    "\n",
    "    start = paths[0][0][0]\n",
    "    end = paths[0][0][-1]\n",
    "\n",
    "    best_path = paths[0][0]\n",
    "    edges = [(best_path[i], best_path[i + 1]) for i in range(len(best_path) - 1)]\n",
    "\n",
    "    subV = []\n",
    "    for p in paths[:20]:\n",
    "        subV += p[0]\n",
    "    \n",
    "    subV = list(set(subV))\n",
    "    subG = g.subgraph(subV)\n",
    "\n",
    "    pos = nx.spring_layout(subG)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    node_colors = ['red' if v == start else 'blue' if v == end else 'gray' for v in subG.nodes()]\n",
    "    edge_colors = ['red' if (edge[0], edge[1]) in edges or (edge[1], edge[0]) in edges else 'gray' for edge in subG.edges()]\n",
    "    edge_widths = [subG[edge[0]][edge[1]]['num_common_partners'] if 'num_common_partners' in subG[edge[0]][edge[1]] else 1.0 for edge in subG.edges()]\n",
    "\n",
    "    nx.draw(subG, pos, with_labels=True, font_weight='bold', node_color=node_colors, edge_color=edge_colors, width=edge_widths)\n",
    "\n",
    "    edge_labels = nx.get_edge_attributes(subG, 'num_common_partners')\n",
    "    nx.draw_networkx_edge_labels(subG, pos, edge_labels=edge_labels)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top5(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_paths_by_partners(g, source, max_path_length=None):\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for node in g.nodes():\n",
    "\n",
    "        if node != source:\n",
    "            try:\n",
    "                res.append((find_paths(g, source, node, cut_off=max_path_length)[0], source, node))\n",
    "            except:\n",
    "                res.append(([float('inf'), float('inf')], source, node))\n",
    "    \n",
    "    def sorting_key(tup):\n",
    "        return (tup[0][-2], -tup[0][-1])\n",
    "    \n",
    "    return pd.DataFrame(sorted(res, key=sorting_key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rank_paths_by_partners(g, '13930213', max_path_length=5)\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
